{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf924ae6",
   "metadata": {},
   "source": [
    "# PySpark Avazu Pipeline\\nThis notebook mirrors the code pipeline: install, init Spark, EDA, train, infer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed in a fresh environment:\n",
    "# !pip install -r ../requirements.txt\n",
    "\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"AvazuNotebook\")\n",
    "         .master(\"local[*]\")\n",
    "         .config(\"spark.driver.memory\", \"6g\")\n",
    "         .getOrCreate())\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(\"Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db78ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIR = \"../data\"\n",
    "TRAIN = f\"{DATA_DIR}/train.gz\"\n",
    "TEST  = f\"{DATA_DIR}/test.gz\"\n",
    "\n",
    "# Basic EDA (sampled for speed)\n",
    "df = spark.read.csv(TRAIN, header=True, inferSchema=True)\n",
    "print(\"Train rows (approx):\", df.count())\n",
    "df.select(\"click\").groupBy(\"click\").count().show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engineering import prepare_dataframe, build_feature_pipeline\n",
    "from training import train_model\n",
    "from inference import run_inference\n",
    "\n",
    "df = spark.read.csv(TRAIN, header=True, inferSchema=True)\n",
    "df = prepare_dataframe(df)\n",
    "model, metrics = train_model(spark, TRAIN, sample_fraction=0.02)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f74b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference to submission\n",
    "run_inference(model, spark, TEST, out_path=\"../submissions/submission_nb\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
